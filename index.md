# MA5 LLM Guardrail Project Inspiration


**By**: Phu Dang (pndang@ucsd.edu)


**Section**: B07 | Mentors: Abed El-Husseini, Nimu Sidhu


**Industry Partner**: Deloitte


**Host Institution**: Halicioglu Data Science Institute


**Prospective Data & Service Providers**: UC San Diego, Qualcomm Institute, Locbit, and more


**Q & A**:

1. **What is the most interesting topic covered in your domain this quarter?**

I personally was very intrigued and interested in learning novel enterprise applications of LLMs and LLM guardrails by leveraging the unique lectures, guest talks, office hours, and exposure provided by my industry mentors at Deloitte. Not only exciting and novel applications, what I am interested in exploring most were the relevant **challenges** facing the wide and effective adoption of Generative AI, specifically large language models, at enterprises. This is because challenges are important problems, which provide **opportunitites** to provide a novel solution. Three of such challenges that I plan to tackle across my Q1 and Q2 projects are (1) scattered, multimodal data sources, (2) IoT data payload privacy, and (3) risk-mitigation for chatbot-user interactions. 

2. **Describe a potential investigation you would like to pursue for your Quarter 2 Project**

A central part of my Quarter 2 project will be conceptualizing, designing, and implementing the chatbot-user interaction flows. Effectively executing this part will allow my team to architect a system that is useful, robust, fault tolerant, and achieve our overarching goal of mitigating risks for Generative AI. Specifically, we will spend much effort figuring out the different situations users may be in as they interact with the LLM, different prospective scenarios of data leakage/risk/brand harm, and how we want to address the prior point, such as returning a controlled/scripted response for safety or judiciously deny service. By figuring this roadmap of relevant interaction scenarios our users may face, we aim to create a powerful and exciting LLM-based tool that enhances the relationship between our users and their data.

3. **What is a potential change you'd make to the approach taken in your current Quarter 1 Project?**

I would not change but I would rather add to my Quarter 1 project, which I like to conduct comparative analysis across various cloud-based LLM guardrail providers, such as those hosted on IBM WatsonX, Databricks, AWS, Azure, rather than on-premise guardrails ran locally. This is because cloud-based solutions are quite popular and increasingly adopted by smaller- to medium-sized enterprises. Cloud solutions are also more scalable and secure, which would introduce an entirely different level of security measures to my project. Similar to my current plan, I would assess the effectiveness, ease-of-implementation, robustness, latency, among other factors between cloud-based LLM guardrail frameworks. Due to time constraints and the need to focus on local guardrails implementation in preperation for my Quarter 2 project, I will save this for the future.

4. **What other techniques would you be interested in using in your [Quarter 2] project?**

Similar to BlockBazaar, a past HDSI Capstone project focused on smart contracts for e-commerce transactions, I am looking forward to incorporating a business lens to the work my team will do in the Quarter 2 project. This is why I personally invested such a deep focus on enterprise impact and real-world applications. I aspire to carry this project forward in entrepreneurial and start-up investment pursuits, providing an effective risk-mitigation solution for enterprises, from mom-and-pops to mid-sized and large enterprises, who are looking to develop or incorporate Artificial Intelligence into their business. In terms of specific techniques, I seek to start thinking about finance (i.e. business-purpose private equity financing), Software-as-a-Service solutions (i.e. web interface), and user experience (i.e. latency, effectiveness, ease-of-use) to maximize the project's potential at capitalization. 
